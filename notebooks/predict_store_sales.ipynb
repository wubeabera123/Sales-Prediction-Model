{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import numpy as np  # Make sure numpy is imported\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='../logs/predict_store_sales.log',\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "  \n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))\n",
    "from load_data import Load_Data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data sets(train and store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from ../data/combined_store_data.csv\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Load cleaned store data\")\n",
    "\n",
    "# Create an instance of CSVReader\n",
    "df = Load_Data('../data/combined_store_data.csv')\n",
    "\n",
    "# Load the data\n",
    "df.load_data()\n",
    "\n",
    "# Get the loaded data\n",
    "df = df.get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      1         c          a               1270.0                        9.0   \n",
      "2      1         c          a               1270.0                        9.0   \n",
      "3      1         c          a               1270.0                        9.0   \n",
      "4      1         c          a               1270.0                        9.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2008.0       0              NaN              NaN   \n",
      "2                    2008.0       0              NaN              NaN   \n",
      "3                    2008.0       0              NaN              NaN   \n",
      "4                    2008.0       0              NaN              NaN   \n",
      "\n",
      "  PromoInterval  DayOfWeek        Date  Sales  Customers  Open  Promo  \\\n",
      "0           NaN          5  2015-07-31   5263        555     1      1   \n",
      "1           NaN          4  2015-07-30   5020        546     1      1   \n",
      "2           NaN          3  2015-07-29   4782        523     1      1   \n",
      "3           NaN          2  2015-07-28   5011        560     1      1   \n",
      "4           NaN          1  2015-07-27   6102        612     1      1   \n",
      "\n",
      "  StateHoliday  SchoolHoliday  \n",
      "0            0              1  \n",
      "1            0              1  \n",
      "2            0              1  \n",
      "3            0              1  \n",
      "4            0              1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1               1270.0                        9.0   \n",
      "1      1               1270.0                        9.0   \n",
      "2      1               1270.0                        9.0   \n",
      "3      1               1270.0                        9.0   \n",
      "4      1               1270.0                        9.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2008.0       0              NaN              NaN   \n",
      "2                    2008.0       0              NaN              NaN   \n",
      "3                    2008.0       0              NaN              NaN   \n",
      "4                    2008.0       0              NaN              NaN   \n",
      "\n",
      "  PromoInterval  DayOfWeek        Date  ...  Promo  SchoolHoliday  \\\n",
      "0           NaN          5  2015-07-31  ...      1              1   \n",
      "1           NaN          4  2015-07-30  ...      1              1   \n",
      "2           NaN          3  2015-07-29  ...      1              1   \n",
      "3           NaN          2  2015-07-28  ...      1              1   \n",
      "4           NaN          1  2015-07-27  ...      1              1   \n",
      "\n",
      "   StoreType_b  StoreType_c  StoreType_d  Assortment_b  Assortment_c  \\\n",
      "0        False         True        False         False         False   \n",
      "1        False         True        False         False         False   \n",
      "2        False         True        False         False         False   \n",
      "3        False         True        False         False         False   \n",
      "4        False         True        False         False         False   \n",
      "\n",
      "   StateHoliday_a  StateHoliday_b  StateHoliday_c  \n",
      "0           False           False           False  \n",
      "1           False           False           False  \n",
      "2           False           False           False  \n",
      "3           False           False           False  \n",
      "4           False           False           False  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logging.info('Starting preprocessing with updated dataframe')\n",
    "# One-hot encode StoreType, Assortment, and StateHoliday\n",
    "df = pd.get_dummies(df, columns=['StoreType', 'Assortment', 'StateHoliday'], drop_first=True)\n",
    "logging.info('One-hot encoded StoreType, Assortment, and StateHoliday columns')\n",
    "\n",
    "# Check result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Handle Competition and Promo2 Features & missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Promo2SinceWeek  Promo2SinceYear PromoInterval\n",
      "0              0.0              0.0          None\n",
      "1              0.0              0.0          None\n",
      "2              0.0              0.0          None\n",
      "3              0.0              0.0          None\n",
      "4              0.0              0.0          None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wubeshet.abera\\AppData\\Local\\Temp\\ipykernel_19928\\237365783.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Promo2SinceWeek'].fillna(0, inplace=True)\n",
      "C:\\Users\\wubeshet.abera\\AppData\\Local\\Temp\\ipykernel_19928\\237365783.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Promo2SinceYear'].fillna(0, inplace=True)\n",
      "C:\\Users\\wubeshet.abera\\AppData\\Local\\Temp\\ipykernel_19928\\237365783.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['PromoInterval'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "logging.info('Handling missing values for Promo2SinceWeek, Promo2SinceYear, and PromoInterval')\n",
    "\n",
    "# Fill missing values for Promo2SinceWeek and Promo2SinceYear with 0 (no promotion)\n",
    "df['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "df['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "\n",
    "# Fill missing PromoInterval with 'None'\n",
    "df['PromoInterval'].fillna('None', inplace=True)\n",
    "logging.info('Filled missing values in Promo2SinceWeek, Promo2SinceYear, and PromoInterval')\n",
    "\n",
    "# Check result\n",
    "print(df[['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction from Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logging.info('Extracting features from the Date column')\n",
    "\n",
    "# Convert 'Date' to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract weekday\n",
    "df['DayOfWeek'] = df['Date'].dt.weekday + 1  # Monday=1, Sunday=7\n",
    "\n",
    "# Extract is_weekend (1 if weekend, 0 if weekday)\n",
    "df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "# Check if it's beginning, mid, or end of the month\n",
    "df['MonthDay'] = df['Date'].dt.day\n",
    "df['IsBeginningOfMonth'] = df['MonthDay'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "df['IsMidMonth'] = df['MonthDay'].apply(lambda x: 1 if 10 < x <= 20 else 0)\n",
    "df['IsEndOfMonth'] = df['MonthDay'].apply(lambda x: 1 if x > 20 else 0)\n",
    "\n",
    "logging.info('Extracted day of week, weekend indicator, and month-day-related features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sales  CompetitionDistance  Promo2SinceWeek  Promo2SinceYear\n",
      "0 -0.132683            -0.539198        -0.760097        -1.001128\n",
      "1 -0.195801            -0.539198        -0.760097        -1.001128\n",
      "2 -0.257620            -0.539198        -0.760097        -1.001128\n",
      "3 -0.198139            -0.539198        -0.760097        -1.001128\n",
      "4  0.085244            -0.539198        -0.760097        -1.001128\n"
     ]
    }
   ],
   "source": [
    "logging.info('Starting to scale numeric features')\n",
    "\n",
    "# Define features to scale\n",
    "features_to_scale = ['Sales', 'CompetitionDistance', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "logging.info('Scaled features: Sales, CompetitionDistance, Promo2SinceWeek, and Promo2SinceYear')\n",
    "\n",
    "# Check result\n",
    "print(df[features_to_scale].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1            -0.539198                        9.0   \n",
      "1      1            -0.539198                        9.0   \n",
      "2      1            -0.539198                        9.0   \n",
      "3      1            -0.539198                        9.0   \n",
      "4      1            -0.539198                        9.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0        -0.760097        -1.001128   \n",
      "1                    2008.0       0        -0.760097        -1.001128   \n",
      "2                    2008.0       0        -0.760097        -1.001128   \n",
      "3                    2008.0       0        -0.760097        -1.001128   \n",
      "4                    2008.0       0        -0.760097        -1.001128   \n",
      "\n",
      "  PromoInterval  DayOfWeek       Date  ...  Assortment_b  Assortment_c  \\\n",
      "0          None          5 2015-07-31  ...         False         False   \n",
      "1          None          4 2015-07-30  ...         False         False   \n",
      "2          None          3 2015-07-29  ...         False         False   \n",
      "3          None          2 2015-07-28  ...         False         False   \n",
      "4          None          1 2015-07-27  ...         False         False   \n",
      "\n",
      "   StateHoliday_a  StateHoliday_b  StateHoliday_c  IsWeekend  MonthDay  \\\n",
      "0           False           False           False          0        31   \n",
      "1           False           False           False          0        30   \n",
      "2           False           False           False          0        29   \n",
      "3           False           False           False          0        28   \n",
      "4           False           False           False          0        27   \n",
      "\n",
      "   IsBeginningOfMonth  IsMidMonth  IsEndOfMonth  \n",
      "0                   0           0             1  \n",
      "1                   0           0             1  \n",
      "2                   0           0             1  \n",
      "3                   0           0             1  \n",
      "4                   0           0             1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "logging.info('Preprocessing completed and dataset is ready for modeling')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models with Sklearn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Log feature importance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m---> 51\u001b[0m important_features \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_importances\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importances: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimportant_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Sales-Prediction-Model\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Sales-Prediction-Model\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Sales-Prediction-Model\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Sales-Prediction-Model\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Data Preparation: Assuming you have a DataFrame 'df' ready with preprocessed data\n",
    "# Extract the features and target\n",
    "X = df.drop(['Sales', 'Date'], axis=1)  # Dropping 'Sales' and 'Date' since Sales is the target\n",
    "y = df['Sales']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Log the shape of the dataset\n",
    "logging.info(f\"Training data shape: {X_train.shape}\")\n",
    "logging.info(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Define the preprocessing pipeline (e.g., scaling)\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a pipeline that first applies the preprocessor and then fits the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Log the pipeline setup\n",
    "logging.info(\"Pipeline created with StandardScaler and RandomForestRegressor.\")\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Log after fitting the model\n",
    "logging.info(\"Model training completed.\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Log prediction completion\n",
    "logging.info(\"Model prediction completed.\")\n",
    "\n",
    "# Evaluate the model performance (using RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "logging.info(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Log feature importance\n",
    "feature_importances = model.feature_importances_\n",
    "important_features = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "logging.info(f\"Feature importances: {important_features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
