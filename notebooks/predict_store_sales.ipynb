{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import numpy as np  # Make sure numpy is imported\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='../logs/predict_store_sales.log',\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "  \n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))\n",
    "from load_data import Load_Data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data sets(train and store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from ../data/combined_store_data.csv\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Load cleaned store data\")\n",
    "\n",
    "# Create an instance of CSVReader\n",
    "df = Load_Data('../data/combined_store_data.csv')\n",
    "\n",
    "# Load the data\n",
    "df.load_data()\n",
    "\n",
    "# Get the loaded data\n",
    "df = df.get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      1         c          a               1270.0                        9.0   \n",
      "2      1         c          a               1270.0                        9.0   \n",
      "3      1         c          a               1270.0                        9.0   \n",
      "4      1         c          a               1270.0                        9.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2008.0       0              NaN              NaN   \n",
      "2                    2008.0       0              NaN              NaN   \n",
      "3                    2008.0       0              NaN              NaN   \n",
      "4                    2008.0       0              NaN              NaN   \n",
      "\n",
      "  PromoInterval  DayOfWeek        Date  Sales  Customers  Open  Promo  \\\n",
      "0           NaN          5  2015-07-31   5263        555     1      1   \n",
      "1           NaN          4  2015-07-30   5020        546     1      1   \n",
      "2           NaN          3  2015-07-29   4782        523     1      1   \n",
      "3           NaN          2  2015-07-28   5011        560     1      1   \n",
      "4           NaN          1  2015-07-27   6102        612     1      1   \n",
      "\n",
      "  StateHoliday  SchoolHoliday  \n",
      "0            0              1  \n",
      "1            0              1  \n",
      "2            0              1  \n",
      "3            0              1  \n",
      "4            0              1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1               1270.0                        9.0   \n",
      "1      1               1270.0                        9.0   \n",
      "2      1               1270.0                        9.0   \n",
      "3      1               1270.0                        9.0   \n",
      "4      1               1270.0                        9.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2008.0       0              NaN              NaN   \n",
      "2                    2008.0       0              NaN              NaN   \n",
      "3                    2008.0       0              NaN              NaN   \n",
      "4                    2008.0       0              NaN              NaN   \n",
      "\n",
      "  PromoInterval  DayOfWeek        Date  ...  Promo  SchoolHoliday  \\\n",
      "0           NaN          5  2015-07-31  ...      1              1   \n",
      "1           NaN          4  2015-07-30  ...      1              1   \n",
      "2           NaN          3  2015-07-29  ...      1              1   \n",
      "3           NaN          2  2015-07-28  ...      1              1   \n",
      "4           NaN          1  2015-07-27  ...      1              1   \n",
      "\n",
      "   StoreType_b  StoreType_c  StoreType_d  Assortment_b  Assortment_c  \\\n",
      "0        False         True        False         False         False   \n",
      "1        False         True        False         False         False   \n",
      "2        False         True        False         False         False   \n",
      "3        False         True        False         False         False   \n",
      "4        False         True        False         False         False   \n",
      "\n",
      "   StateHoliday_a  StateHoliday_b  StateHoliday_c  \n",
      "0           False           False           False  \n",
      "1           False           False           False  \n",
      "2           False           False           False  \n",
      "3           False           False           False  \n",
      "4           False           False           False  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logging.info('Starting preprocessing with updated dataframe')\n",
    "# One-hot encode StoreType, Assortment, and StateHoliday\n",
    "df = pd.get_dummies(df, columns=['StoreType', 'Assortment', 'StateHoliday'], drop_first=True)\n",
    "logging.info('One-hot encoded StoreType, Assortment, and StateHoliday columns')\n",
    "\n",
    "# Check result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Handle Competition and Promo2 Features & missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wubeshet.abera\\AppData\\Local\\Temp\\ipykernel_21352\\237365783.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Promo2SinceWeek'].fillna(0, inplace=True)\n",
      "C:\\Users\\wubeshet.abera\\AppData\\Local\\Temp\\ipykernel_21352\\237365783.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Promo2SinceYear'].fillna(0, inplace=True)\n",
      "C:\\Users\\wubeshet.abera\\AppData\\Local\\Temp\\ipykernel_21352\\237365783.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['PromoInterval'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Promo2SinceWeek  Promo2SinceYear PromoInterval\n",
      "0              0.0              0.0          None\n",
      "1              0.0              0.0          None\n",
      "2              0.0              0.0          None\n",
      "3              0.0              0.0          None\n",
      "4              0.0              0.0          None\n"
     ]
    }
   ],
   "source": [
    "logging.info('Handling missing values for Promo2SinceWeek, Promo2SinceYear, and PromoInterval')\n",
    "\n",
    "# Fill missing values for Promo2SinceWeek and Promo2SinceYear with 0 (no promotion)\n",
    "df['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "df['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "\n",
    "# Fill missing PromoInterval with 'None'\n",
    "df['PromoInterval'].fillna('None', inplace=True)\n",
    "logging.info('Filled missing values in Promo2SinceWeek, Promo2SinceYear, and PromoInterval')\n",
    "\n",
    "# Check result\n",
    "print(df[['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction from Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logging.info('Extracting features from the Date column')\n",
    "\n",
    "# Convert 'Date' to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract weekday\n",
    "df['DayOfWeek'] = df['Date'].dt.weekday + 1  # Monday=1, Sunday=7\n",
    "\n",
    "# Extract is_weekend (1 if weekend, 0 if weekday)\n",
    "df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "# Check if it's beginning, mid, or end of the month\n",
    "df['MonthDay'] = df['Date'].dt.day\n",
    "df['IsBeginningOfMonth'] = df['MonthDay'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "df['IsMidMonth'] = df['MonthDay'].apply(lambda x: 1 if 10 < x <= 20 else 0)\n",
    "df['IsEndOfMonth'] = df['MonthDay'].apply(lambda x: 1 if x > 20 else 0)\n",
    "\n",
    "logging.info('Extracted day of week, weekend indicator, and month-day-related features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sales  CompetitionDistance  Promo2SinceWeek  Promo2SinceYear\n",
      "0 -0.132683            -0.539198        -0.760097        -1.001128\n",
      "1 -0.195801            -0.539198        -0.760097        -1.001128\n",
      "2 -0.257620            -0.539198        -0.760097        -1.001128\n",
      "3 -0.198139            -0.539198        -0.760097        -1.001128\n",
      "4  0.085244            -0.539198        -0.760097        -1.001128\n"
     ]
    }
   ],
   "source": [
    "logging.info('Starting to scale numeric features')\n",
    "\n",
    "# Define features to scale\n",
    "features_to_scale = ['Sales', 'CompetitionDistance', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "logging.info('Scaled features: Sales, CompetitionDistance, Promo2SinceWeek, and Promo2SinceYear')\n",
    "\n",
    "# Check result\n",
    "print(df[features_to_scale].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1            -0.539198                        9.0   \n",
      "1      1            -0.539198                        9.0   \n",
      "2      1            -0.539198                        9.0   \n",
      "3      1            -0.539198                        9.0   \n",
      "4      1            -0.539198                        9.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0        -0.760097        -1.001128   \n",
      "1                    2008.0       0        -0.760097        -1.001128   \n",
      "2                    2008.0       0        -0.760097        -1.001128   \n",
      "3                    2008.0       0        -0.760097        -1.001128   \n",
      "4                    2008.0       0        -0.760097        -1.001128   \n",
      "\n",
      "  PromoInterval  DayOfWeek       Date  ...  Assortment_b  Assortment_c  \\\n",
      "0          None          5 2015-07-31  ...         False         False   \n",
      "1          None          4 2015-07-30  ...         False         False   \n",
      "2          None          3 2015-07-29  ...         False         False   \n",
      "3          None          2 2015-07-28  ...         False         False   \n",
      "4          None          1 2015-07-27  ...         False         False   \n",
      "\n",
      "   StateHoliday_a  StateHoliday_b  StateHoliday_c  IsWeekend  MonthDay  \\\n",
      "0           False           False           False          0        31   \n",
      "1           False           False           False          0        30   \n",
      "2           False           False           False          0        29   \n",
      "3           False           False           False          0        28   \n",
      "4           False           False           False          0        27   \n",
      "\n",
      "   IsBeginningOfMonth  IsMidMonth  IsEndOfMonth  \n",
      "0                   0           0             1  \n",
      "1                   0           0             1  \n",
      "2                   0           0             1  \n",
      "3                   0           0             1  \n",
      "4                   0           0             1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "logging.info('Preprocessing completed and dataset is ready for modeling')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models with Sklearn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Drop 'Sales' and 'Date' columns, 'Sales' is the target variable\n",
    "X = df.drop(['Sales', 'Date'], axis=1)\n",
    "y = df['Sales']\n",
    "\n",
    "# Check for missing values in X\n",
    "logging.info(f\"Missing values in X before preprocessing: \\n{X.isnull().sum()}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Log the shape of the dataset\n",
    "logging.info(f\"Training data shape: {X_train.shape}\")\n",
    "logging.info(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_features = ['Store', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "                    'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', \n",
    "                    'Promo2SinceYear', 'DayOfWeek', 'MonthDay', \n",
    "                    'IsWeekend', 'IsBeginningOfMonth', 'IsMidMonth', 'IsEndOfMonth']\n",
    "\n",
    "categorical_features = ['PromoInterval', 'Assortment_b', 'Assortment_c', \n",
    "                        'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c']\n",
    "\n",
    "# Define the preprocessing pipeline: scaling for numeric, one-hot encoding for categorical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a pipeline that applies the preprocessor and then fits the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Log the pipeline setup\n",
    "logging.info(\"Pipeline created with StandardScaler, OneHotEncoder, and RandomForestRegressor.\")\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Log after fitting the model\n",
    "logging.info(\"Model training completed.\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Log prediction completion\n",
    "logging.info(\"Model prediction completed.\")\n",
    "\n",
    "# Evaluate the model performance (using RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "logging.info(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Evaluate the model performance (using MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "logging.info(f\"Test MAE: {mae:.4f}\")\n",
    "\n",
    "# Extract feature importances (note: this will work only if the model supports it)\n",
    "model = pipeline.named_steps['model']  # Get the trained model from the pipeline\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    feature_importances = model.feature_importances_\n",
    "    # Get feature names after preprocessing (this includes one-hot encoded feature names)\n",
    "    feature_names = numeric_features + list(pipeline.named_steps['preprocessor']\n",
    "                                            .named_transformers_['cat']\n",
    "                                            .get_feature_names_out(categorical_features))\n",
    "    \n",
    "    important_features = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    logging.info(f\"Feature importances: {important_features}\")\n",
    "else:\n",
    "    logging.info(\"The model does not support feature importance extraction.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
